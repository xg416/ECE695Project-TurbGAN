{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c3e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from UNet3d import UNet3D\n",
    "from utils import *\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e33df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_net = UNet3D(n_frames=10, feat_channels=[32, 128, 128, 256, 512],).cuda().train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03886895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1     [-1, 32, 10, 128, 128]           2,624\n",
      "         LayerNorm-2           [-1, 163840, 32]              64\n",
      "       LayerNorm3D-3     [-1, 32, 10, 128, 128]               0\n",
      "              GELU-4     [-1, 32, 10, 128, 128]               0\n",
      "            Conv3d-5     [-1, 32, 10, 128, 128]          27,680\n",
      "         LayerNorm-6           [-1, 163840, 32]              64\n",
      "       LayerNorm3D-7     [-1, 32, 10, 128, 128]               0\n",
      "              GELU-8     [-1, 32, 10, 128, 128]               0\n",
      "            Conv3d-9     [-1, 32, 10, 128, 128]              96\n",
      "     Conv3D_Block-10     [-1, 32, 10, 128, 128]               0\n",
      "        MaxPool3d-11       [-1, 32, 10, 64, 64]               0\n",
      "           Conv3d-12       [-1, 32, 10, 64, 64]             896\n",
      "           Conv3d-13      [-1, 128, 10, 64, 64]           4,224\n",
      "         DWconv3D-14      [-1, 128, 10, 64, 64]               0\n",
      "        LayerNorm-15           [-1, 40960, 128]             256\n",
      "      LayerNorm3D-16      [-1, 128, 10, 64, 64]               0\n",
      "             GELU-17      [-1, 128, 10, 64, 64]               0\n",
      "           Conv3d-18      [-1, 128, 10, 64, 64]           3,584\n",
      "           Conv3d-19      [-1, 128, 10, 64, 64]          16,512\n",
      "         DWconv3D-20      [-1, 128, 10, 64, 64]               0\n",
      "        LayerNorm-21           [-1, 40960, 128]             256\n",
      "      LayerNorm3D-22      [-1, 128, 10, 64, 64]               0\n",
      "             GELU-23      [-1, 128, 10, 64, 64]               0\n",
      "           Conv3d-24       [-1, 32, 10, 64, 64]              32\n",
      "           Conv3d-25      [-1, 128, 10, 64, 64]           4,224\n",
      "         DWconv3D-26      [-1, 128, 10, 64, 64]               0\n",
      "     Conv3D_Block-27      [-1, 128, 10, 64, 64]               0\n",
      "        MaxPool3d-28      [-1, 128, 10, 32, 32]               0\n",
      "           Conv3d-29      [-1, 128, 10, 32, 32]           3,584\n",
      "           Conv3d-30      [-1, 128, 10, 32, 32]          16,512\n",
      "         DWconv3D-31      [-1, 128, 10, 32, 32]               0\n",
      "        LayerNorm-32           [-1, 10240, 128]             256\n",
      "      LayerNorm3D-33      [-1, 128, 10, 32, 32]               0\n",
      "             GELU-34      [-1, 128, 10, 32, 32]               0\n",
      "           Conv3d-35      [-1, 128, 10, 32, 32]           3,584\n",
      "           Conv3d-36      [-1, 128, 10, 32, 32]          16,512\n",
      "         DWconv3D-37      [-1, 128, 10, 32, 32]               0\n",
      "        LayerNorm-38           [-1, 10240, 128]             256\n",
      "      LayerNorm3D-39      [-1, 128, 10, 32, 32]               0\n",
      "             GELU-40      [-1, 128, 10, 32, 32]               0\n",
      "           Conv3d-41      [-1, 128, 10, 32, 32]             128\n",
      "           Conv3d-42      [-1, 128, 10, 32, 32]          16,512\n",
      "         DWconv3D-43      [-1, 128, 10, 32, 32]               0\n",
      "     Conv3D_Block-44      [-1, 128, 10, 32, 32]               0\n",
      "        MaxPool3d-45      [-1, 128, 10, 16, 16]               0\n",
      "           Conv3d-46      [-1, 128, 10, 16, 16]           3,584\n",
      "           Conv3d-47      [-1, 256, 10, 16, 16]          33,024\n",
      "         DWconv3D-48      [-1, 256, 10, 16, 16]               0\n",
      "        LayerNorm-49            [-1, 2560, 256]             512\n",
      "      LayerNorm3D-50      [-1, 256, 10, 16, 16]               0\n",
      "             GELU-51      [-1, 256, 10, 16, 16]               0\n",
      "           Conv3d-52      [-1, 256, 10, 16, 16]           7,168\n",
      "           Conv3d-53      [-1, 256, 10, 16, 16]          65,792\n",
      "         DWconv3D-54      [-1, 256, 10, 16, 16]               0\n",
      "        LayerNorm-55            [-1, 2560, 256]             512\n",
      "      LayerNorm3D-56      [-1, 256, 10, 16, 16]               0\n",
      "             GELU-57      [-1, 256, 10, 16, 16]               0\n",
      "           Conv3d-58      [-1, 128, 10, 16, 16]             128\n",
      "           Conv3d-59      [-1, 256, 10, 16, 16]          33,024\n",
      "         DWconv3D-60      [-1, 256, 10, 16, 16]               0\n",
      "     Conv3D_Block-61      [-1, 256, 10, 16, 16]               0\n",
      "        MaxPool3d-62        [-1, 256, 10, 8, 8]               0\n",
      "           Conv3d-63        [-1, 256, 10, 8, 8]           7,168\n",
      "           Conv3d-64        [-1, 512, 10, 8, 8]         131,584\n",
      "         DWconv3D-65        [-1, 512, 10, 8, 8]               0\n",
      "        LayerNorm-66             [-1, 640, 512]           1,024\n",
      "      LayerNorm3D-67        [-1, 512, 10, 8, 8]               0\n",
      "             GELU-68        [-1, 512, 10, 8, 8]               0\n",
      "           Conv3d-69        [-1, 512, 10, 8, 8]          14,336\n",
      "           Conv3d-70        [-1, 512, 10, 8, 8]         262,656\n",
      "         DWconv3D-71        [-1, 512, 10, 8, 8]               0\n",
      "        LayerNorm-72             [-1, 640, 512]           1,024\n",
      "      LayerNorm3D-73        [-1, 512, 10, 8, 8]               0\n",
      "             GELU-74        [-1, 512, 10, 8, 8]               0\n",
      "           Conv3d-75        [-1, 256, 10, 8, 8]             256\n",
      "           Conv3d-76        [-1, 512, 10, 8, 8]         131,584\n",
      "         DWconv3D-77        [-1, 512, 10, 8, 8]               0\n",
      "     Conv3D_Block-78        [-1, 512, 10, 8, 8]               0\n",
      "        LayerNorm-79             [-1, 640, 512]           1,024\n",
      "      LayerNorm3D-80        [-1, 512, 10, 8, 8]               0\n",
      "  ConvTranspose3d-81      [-1, 512, 10, 16, 16]          14,336\n",
      "           Conv3d-82      [-1, 256, 10, 16, 16]         131,328\n",
      "             GELU-83      [-1, 256, 10, 16, 16]               0\n",
      "   Deconv3D_Block-84      [-1, 256, 10, 16, 16]               0\n",
      "           Conv3d-85      [-1, 512, 10, 16, 16]          14,336\n",
      "           Conv3d-86      [-1, 256, 10, 16, 16]         131,328\n",
      "         DWconv3D-87      [-1, 256, 10, 16, 16]               0\n",
      "        LayerNorm-88            [-1, 2560, 256]             512\n",
      "      LayerNorm3D-89      [-1, 256, 10, 16, 16]               0\n",
      "             GELU-90      [-1, 256, 10, 16, 16]               0\n",
      "           Conv3d-91      [-1, 256, 10, 16, 16]           7,168\n",
      "           Conv3d-92      [-1, 256, 10, 16, 16]          65,792\n",
      "         DWconv3D-93      [-1, 256, 10, 16, 16]               0\n",
      "        LayerNorm-94            [-1, 2560, 256]             512\n",
      "      LayerNorm3D-95      [-1, 256, 10, 16, 16]               0\n",
      "             GELU-96      [-1, 256, 10, 16, 16]               0\n",
      "           Conv3d-97      [-1, 512, 10, 16, 16]             512\n",
      "           Conv3d-98      [-1, 256, 10, 16, 16]         131,328\n",
      "         DWconv3D-99      [-1, 256, 10, 16, 16]               0\n",
      "    Conv3D_Block-100      [-1, 256, 10, 16, 16]               0\n",
      "       LayerNorm-101            [-1, 2560, 256]             512\n",
      "     LayerNorm3D-102      [-1, 256, 10, 16, 16]               0\n",
      " ConvTranspose3d-103      [-1, 256, 10, 32, 32]           7,168\n",
      "          Conv3d-104      [-1, 128, 10, 32, 32]          32,896\n",
      "            GELU-105      [-1, 128, 10, 32, 32]               0\n",
      "  Deconv3D_Block-106      [-1, 128, 10, 32, 32]               0\n",
      "          Conv3d-107      [-1, 256, 10, 32, 32]           7,168\n",
      "          Conv3d-108      [-1, 128, 10, 32, 32]          32,896\n",
      "        DWconv3D-109      [-1, 128, 10, 32, 32]               0\n",
      "       LayerNorm-110           [-1, 10240, 128]             256\n",
      "     LayerNorm3D-111      [-1, 128, 10, 32, 32]               0\n",
      "            GELU-112      [-1, 128, 10, 32, 32]               0\n",
      "          Conv3d-113      [-1, 128, 10, 32, 32]           3,584\n",
      "          Conv3d-114      [-1, 128, 10, 32, 32]          16,512\n",
      "        DWconv3D-115      [-1, 128, 10, 32, 32]               0\n",
      "       LayerNorm-116           [-1, 10240, 128]             256\n",
      "     LayerNorm3D-117      [-1, 128, 10, 32, 32]               0\n",
      "            GELU-118      [-1, 128, 10, 32, 32]               0\n",
      "          Conv3d-119      [-1, 256, 10, 32, 32]             256\n",
      "          Conv3d-120      [-1, 128, 10, 32, 32]          32,896\n",
      "        DWconv3D-121      [-1, 128, 10, 32, 32]               0\n",
      "    Conv3D_Block-122      [-1, 128, 10, 32, 32]               0\n",
      "       LayerNorm-123           [-1, 10240, 128]             256\n",
      "     LayerNorm3D-124      [-1, 128, 10, 32, 32]               0\n",
      " ConvTranspose3d-125      [-1, 128, 10, 64, 64]           3,584\n",
      "          Conv3d-126      [-1, 128, 10, 64, 64]          16,512\n",
      "            GELU-127      [-1, 128, 10, 64, 64]               0\n",
      "  Deconv3D_Block-128      [-1, 128, 10, 64, 64]               0\n",
      "          Conv3d-129      [-1, 256, 10, 64, 64]           7,168\n",
      "          Conv3d-130      [-1, 128, 10, 64, 64]          32,896\n",
      "        DWconv3D-131      [-1, 128, 10, 64, 64]               0\n",
      "       LayerNorm-132           [-1, 40960, 128]             256\n",
      "     LayerNorm3D-133      [-1, 128, 10, 64, 64]               0\n",
      "            GELU-134      [-1, 128, 10, 64, 64]               0\n",
      "          Conv3d-135      [-1, 128, 10, 64, 64]           3,584\n",
      "          Conv3d-136      [-1, 128, 10, 64, 64]          16,512\n",
      "        DWconv3D-137      [-1, 128, 10, 64, 64]               0\n",
      "       LayerNorm-138           [-1, 40960, 128]             256\n",
      "     LayerNorm3D-139      [-1, 128, 10, 64, 64]               0\n",
      "            GELU-140      [-1, 128, 10, 64, 64]               0\n",
      "          Conv3d-141      [-1, 256, 10, 64, 64]             256\n",
      "          Conv3d-142      [-1, 128, 10, 64, 64]          32,896\n",
      "        DWconv3D-143      [-1, 128, 10, 64, 64]               0\n",
      "    Conv3D_Block-144      [-1, 128, 10, 64, 64]               0\n",
      "       LayerNorm-145           [-1, 40960, 128]             256\n",
      "     LayerNorm3D-146      [-1, 128, 10, 64, 64]               0\n",
      " ConvTranspose3d-147    [-1, 128, 10, 128, 128]           3,584\n",
      "          Conv3d-148     [-1, 32, 10, 128, 128]           4,128\n",
      "            GELU-149     [-1, 32, 10, 128, 128]               0\n",
      "  Deconv3D_Block-150     [-1, 32, 10, 128, 128]               0\n",
      "          Conv3d-151     [-1, 64, 10, 128, 128]           1,792\n",
      "          Conv3d-152     [-1, 32, 10, 128, 128]           2,080\n",
      "        DWconv3D-153     [-1, 32, 10, 128, 128]               0\n",
      "       LayerNorm-154           [-1, 163840, 32]              64\n",
      "     LayerNorm3D-155     [-1, 32, 10, 128, 128]               0\n",
      "            GELU-156     [-1, 32, 10, 128, 128]               0\n",
      "          Conv3d-157     [-1, 32, 10, 128, 128]             896\n",
      "          Conv3d-158     [-1, 32, 10, 128, 128]           1,056\n",
      "        DWconv3D-159     [-1, 32, 10, 128, 128]               0\n",
      "       LayerNorm-160           [-1, 163840, 32]              64\n",
      "     LayerNorm3D-161     [-1, 32, 10, 128, 128]               0\n",
      "            GELU-162     [-1, 32, 10, 128, 128]               0\n",
      "          Conv3d-163     [-1, 64, 10, 128, 128]              64\n",
      "          Conv3d-164     [-1, 32, 10, 128, 128]           2,080\n",
      "        DWconv3D-165     [-1, 32, 10, 128, 128]               0\n",
      "    Conv3D_Block-166     [-1, 32, 10, 128, 128]               0\n",
      "       LayerNorm-167           [-1, 163840, 32]              64\n",
      "     LayerNorm3D-168     [-1, 32, 10, 128, 128]               0\n",
      "          Conv3d-169     [-1, 32, 10, 128, 128]           1,056\n",
      "          Conv3d-170      [-1, 32, 1, 128, 128]           2,912\n",
      "          Conv2d-171          [-1, 3, 128, 128]              96\n",
      "          TMerge-172          [-1, 3, 128, 128]               0\n",
      "================================================================\n",
      "Total params: 1,578,176\n",
      "Trainable params: 1,578,176\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.88\n",
      "Forward/backward pass size (MB): 3741.00\n",
      "Params size (MB): 6.02\n",
      "Estimated Total Size (MB): 3748.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(gen_net, (3,10,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34a3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import DataLoaderTurb\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoaderTurb('./image2/img2')\n",
    "train_loader = DataLoader(dataset=dataloader, batch_size=20, \\\n",
    "                          shuffle=True, num_workers=8, drop_last=True, pin_memory=True)\n",
    "# mean_im = data.mean(0).permute(1,2,0).clamp(0,1).detach().cpu().numpy()\n",
    "# pg_save = Image.fromarray(np.uint8(mean_im * 255))\n",
    "# pg_save.save('mean2.jpg', 'JPEG')\n",
    "mean_im = TF.to_tensor(Image.open('./image2/mean.jpg').convert(\"RGB\")).cuda()\n",
    "mean_im = torch.stack([mean_im, mean_im], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173efeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-6\n",
    "max_iters = 10000\n",
    "optimizer = optim.AdamW(gen_net.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-8)\n",
    "scheduler = CosineDecayWithWarmUpScheduler(optimizer, 5, init_warmup_lr=5e-7, \\\n",
    "                                           warm_up_steps=1000,max_lr=lr, min_lr=1e-7,num_step_down=max_iters)\n",
    "criterion_char = CharbonnierLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30462e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 100 lr: 0.00000095 loss-100-iter: 0.23476454 psnr-100-iter: 9.503778\n",
      "iteration: 200 lr: 0.00000140 loss-100-iter: 0.17692056 psnr-100-iter: 11.316060\n",
      "iteration: 300 lr: 0.00000185 loss-100-iter: 0.13901213 psnr-100-iter: 14.167670\n",
      "iteration: 400 lr: 0.00000230 loss-100-iter: 0.09433629 psnr-100-iter: 18.617477\n",
      "iteration: 500 lr: 0.00000275 loss-100-iter: 0.04128907 psnr-100-iter: 26.063072\n",
      "iteration: 600 lr: 0.00000320 loss-100-iter: 0.03906770 psnr-100-iter: 26.434854\n",
      "iteration: 700 lr: 0.00000365 loss-100-iter: 0.06422441 psnr-100-iter: 22.155913\n",
      "iteration: 800 lr: 0.00000410 loss-100-iter: 0.06107317 psnr-100-iter: 22.338365\n",
      "iteration: 900 lr: 0.00000455 loss-100-iter: 0.04134213 psnr-100-iter: 25.431169\n",
      "iteration: 1000 lr: 0.00000500 loss-100-iter: 0.02447659 psnr-100-iter: 29.379364\n",
      "iteration: 1100 lr: 0.00000500 loss-100-iter: 0.03323309 psnr-100-iter: 27.069005\n",
      "iteration: 1200 lr: 0.00000500 loss-100-iter: 0.02195956 psnr-100-iter: 30.047891\n",
      "iteration: 1300 lr: 0.00000499 loss-100-iter: 0.03466775 psnr-100-iter: 27.282940\n",
      "iteration: 1400 lr: 0.00000498 loss-100-iter: 0.03250430 psnr-100-iter: 27.261148\n",
      "iteration: 1500 lr: 0.00000497 loss-100-iter: 0.02960863 psnr-100-iter: 28.508946\n",
      "iteration: 1600 lr: 0.00000496 loss-100-iter: 0.02976454 psnr-100-iter: 28.794496\n",
      "iteration: 1700 lr: 0.00000494 loss-100-iter: 0.02546486 psnr-100-iter: 29.635698\n",
      "iteration: 1800 lr: 0.00000492 loss-100-iter: 0.02984594 psnr-100-iter: 28.358685\n",
      "iteration: 1900 lr: 0.00000490 loss-100-iter: 0.03672318 psnr-100-iter: 27.092681\n",
      "iteration: 2000 lr: 0.00000488 loss-100-iter: 0.02740981 psnr-100-iter: 29.816553\n",
      "iteration: 2100 lr: 0.00000486 loss-100-iter: 0.02143123 psnr-100-iter: 31.175510\n",
      "iteration: 2200 lr: 0.00000483 loss-100-iter: 0.03798624 psnr-100-iter: 27.172876\n",
      "iteration: 2300 lr: 0.00000480 loss-100-iter: 0.03097701 psnr-100-iter: 28.244358\n",
      "iteration: 2400 lr: 0.00000477 loss-100-iter: 0.02513143 psnr-100-iter: 30.292291\n",
      "iteration: 2500 lr: 0.00000473 loss-100-iter: 0.02753663 psnr-100-iter: 29.481942\n",
      "iteration: 2600 lr: 0.00000470 loss-100-iter: 0.03449142 psnr-100-iter: 27.984657\n",
      "iteration: 2700 lr: 0.00000466 loss-100-iter: 0.02943883 psnr-100-iter: 28.770003\n",
      "iteration: 2800 lr: 0.00000462 loss-100-iter: 0.03211536 psnr-100-iter: 28.424174\n",
      "iteration: 2900 lr: 0.00000458 loss-100-iter: 0.02728541 psnr-100-iter: 29.545938\n",
      "iteration: 3000 lr: 0.00000453 loss-100-iter: 0.02744938 psnr-100-iter: 29.683336\n",
      "iteration: 3100 lr: 0.00000449 loss-100-iter: 0.03707681 psnr-100-iter: 27.884165\n",
      "iteration: 3200 lr: 0.00000444 loss-100-iter: 0.02941127 psnr-100-iter: 28.958286\n",
      "iteration: 3300 lr: 0.00000439 loss-100-iter: 0.02796176 psnr-100-iter: 29.625524\n",
      "iteration: 3400 lr: 0.00000434 loss-100-iter: 0.03030806 psnr-100-iter: 29.205657\n",
      "iteration: 3500 lr: 0.00000428 loss-100-iter: 0.03077024 psnr-100-iter: 29.032420\n",
      "iteration: 3600 lr: 0.00000423 loss-100-iter: 0.03207602 psnr-100-iter: 28.715720\n",
      "iteration: 3700 lr: 0.00000417 loss-100-iter: 0.02767983 psnr-100-iter: 29.109178\n",
      "iteration: 3800 lr: 0.00000411 loss-100-iter: 0.02943774 psnr-100-iter: 29.642498\n",
      "iteration: 3900 lr: 0.00000405 loss-100-iter: 0.02698777 psnr-100-iter: 30.331094\n",
      "iteration: 4000 lr: 0.00000399 loss-100-iter: 0.02862416 psnr-100-iter: 29.261234\n",
      "iteration: 4100 lr: 0.00000393 loss-100-iter: 0.02858575 psnr-100-iter: 28.320695\n",
      "iteration: 4200 lr: 0.00000386 loss-100-iter: 0.03212108 psnr-100-iter: 28.751179\n",
      "iteration: 4300 lr: 0.00000380 loss-100-iter: 0.02379420 psnr-100-iter: 30.553383\n",
      "iteration: 4400 lr: 0.00000373 loss-100-iter: 0.02922565 psnr-100-iter: 29.499085\n",
      "iteration: 4500 lr: 0.00000366 loss-100-iter: 0.02487200 psnr-100-iter: 30.158429\n",
      "iteration: 4600 lr: 0.00000359 loss-100-iter: 0.02505251 psnr-100-iter: 30.770456\n",
      "iteration: 4700 lr: 0.00000352 loss-100-iter: 0.02697173 psnr-100-iter: 29.953999\n",
      "iteration: 4800 lr: 0.00000345 loss-100-iter: 0.02516887 psnr-100-iter: 30.157733\n",
      "iteration: 4900 lr: 0.00000338 loss-100-iter: 0.02828702 psnr-100-iter: 30.124018\n",
      "iteration: 5000 lr: 0.00000331 loss-100-iter: 0.02540703 psnr-100-iter: 30.055286\n",
      "iteration: 5100 lr: 0.00000323 loss-100-iter: 0.02407804 psnr-100-iter: 30.526020\n",
      "iteration: 5200 lr: 0.00000316 loss-100-iter: 0.01992655 psnr-100-iter: 32.419054\n",
      "iteration: 5300 lr: 0.00000308 loss-100-iter: 0.02166532 psnr-100-iter: 31.773350\n",
      "iteration: 5400 lr: 0.00000301 loss-100-iter: 0.02716480 psnr-100-iter: 28.730922\n",
      "iteration: 5500 lr: 0.00000293 loss-100-iter: 0.02948150 psnr-100-iter: 27.655415\n",
      "iteration: 5600 lr: 0.00000286 loss-100-iter: 0.02645033 psnr-100-iter: 29.185509\n",
      "iteration: 5700 lr: 0.00000278 loss-100-iter: 0.01521547 psnr-100-iter: 34.367538\n",
      "iteration: 5800 lr: 0.00000270 loss-100-iter: 0.01565796 psnr-100-iter: 34.176062\n",
      "iteration: 5900 lr: 0.00000263 loss-100-iter: 0.02362727 psnr-100-iter: 30.102998\n",
      "iteration: 6000 lr: 0.00000255 loss-100-iter: 0.02509380 psnr-100-iter: 29.302397\n",
      "iteration: 6100 lr: 0.00000247 loss-100-iter: 0.02474691 psnr-100-iter: 30.160346\n",
      "iteration: 6200 lr: 0.00000240 loss-100-iter: 0.02087407 psnr-100-iter: 32.367646\n",
      "iteration: 6300 lr: 0.00000232 loss-100-iter: 0.01581405 psnr-100-iter: 34.394529\n",
      "iteration: 6400 lr: 0.00000224 loss-100-iter: 0.01556417 psnr-100-iter: 34.098789\n",
      "iteration: 6500 lr: 0.00000217 loss-100-iter: 0.01786606 psnr-100-iter: 32.857104\n",
      "iteration: 6600 lr: 0.00000209 loss-100-iter: 0.02162383 psnr-100-iter: 32.096746\n",
      "iteration: 6700 lr: 0.00000202 loss-100-iter: 0.02138661 psnr-100-iter: 32.138955\n",
      "iteration: 6800 lr: 0.00000194 loss-100-iter: 0.01924468 psnr-100-iter: 32.881268\n",
      "iteration: 6900 lr: 0.00000187 loss-100-iter: 0.01623644 psnr-100-iter: 34.353777\n",
      "iteration: 7000 lr: 0.00000179 loss-100-iter: 0.01194212 psnr-100-iter: 36.264635\n",
      "iteration: 7100 lr: 0.00000172 loss-100-iter: 0.01379185 psnr-100-iter: 35.456929\n",
      "iteration: 7200 lr: 0.00000165 loss-100-iter: 0.01794621 psnr-100-iter: 33.388123\n",
      "iteration: 7300 lr: 0.00000158 loss-100-iter: 0.02054871 psnr-100-iter: 32.334841\n",
      "iteration: 7400 lr: 0.00000151 loss-100-iter: 0.01976548 psnr-100-iter: 32.690040\n",
      "iteration: 7500 lr: 0.00000144 loss-100-iter: 0.01577068 psnr-100-iter: 34.487488\n",
      "iteration: 7600 lr: 0.00000137 loss-100-iter: 0.01157043 psnr-100-iter: 36.753372\n",
      "iteration: 7700 lr: 0.00000130 loss-100-iter: 0.01067556 psnr-100-iter: 37.048280\n",
      "iteration: 7800 lr: 0.00000124 loss-100-iter: 0.01327696 psnr-100-iter: 35.689081\n",
      "iteration: 7900 lr: 0.00000117 loss-100-iter: 0.01513226 psnr-100-iter: 34.747493\n",
      "iteration: 8000 lr: 0.00000111 loss-100-iter: 0.01569262 psnr-100-iter: 34.359429\n",
      "iteration: 8100 lr: 0.00000105 loss-100-iter: 0.01562997 psnr-100-iter: 34.402816\n",
      "iteration: 8200 lr: 0.00000099 loss-100-iter: 0.01486875 psnr-100-iter: 34.829792\n",
      "iteration: 8300 lr: 0.00000093 loss-100-iter: 0.01314619 psnr-100-iter: 35.575898\n",
      "iteration: 8400 lr: 0.00000087 loss-100-iter: 0.01115125 psnr-100-iter: 36.565716\n",
      "iteration: 8500 lr: 0.00000082 loss-100-iter: 0.01027103 psnr-100-iter: 37.193113\n",
      "iteration: 8600 lr: 0.00000076 loss-100-iter: 0.01041555 psnr-100-iter: 37.266765\n",
      "iteration: 8700 lr: 0.00000071 loss-100-iter: 0.01150322 psnr-100-iter: 36.661318\n",
      "iteration: 8800 lr: 0.00000066 loss-100-iter: 0.01264872 psnr-100-iter: 36.078941\n",
      "iteration: 8900 lr: 0.00000061 loss-100-iter: 0.01352220 psnr-100-iter: 35.601844\n",
      "iteration: 9000 lr: 0.00000057 loss-100-iter: 0.01338223 psnr-100-iter: 35.731218\n",
      "iteration: 9100 lr: 0.00000052 loss-100-iter: 0.01278997 psnr-100-iter: 36.058158\n",
      "iteration: 9200 lr: 0.00000048 loss-100-iter: 0.01194281 psnr-100-iter: 36.491493\n",
      "iteration: 9300 lr: 0.00000044 loss-100-iter: 0.01068058 psnr-100-iter: 37.293061\n",
      "iteration: 9400 lr: 0.00000040 loss-100-iter: 0.00999375 psnr-100-iter: 37.648111\n",
      "iteration: 9500 lr: 0.00000037 loss-100-iter: 0.00964881 psnr-100-iter: 37.772678\n",
      "iteration: 9600 lr: 0.00000033 loss-100-iter: 0.00965591 psnr-100-iter: 37.656578\n",
      "iteration: 9700 lr: 0.00000030 loss-100-iter: 0.00961767 psnr-100-iter: 37.704772\n",
      "iteration: 9800 lr: 0.00000027 loss-100-iter: 0.01008532 psnr-100-iter: 37.276156\n",
      "iteration: 9900 lr: 0.00000024 loss-100-iter: 0.01018953 psnr-100-iter: 37.247794\n",
      "iteration: 10000 lr: 0.00000022 loss-100-iter: 0.01038216 psnr-100-iter: 37.140436\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "niter = 0\n",
    "\n",
    "current_loss = 0\n",
    "psnr = 0\n",
    "best_psnr = 0\n",
    "loss_mean = []\n",
    "psnr_mean = []\n",
    "while True:\n",
    "    for data in train_loader:\n",
    "        data = data.view((-1, 10, 3, 128, 128)).permute(0,2,1,3,4).cuda()\n",
    "        output = gen_net(data)\n",
    "        \n",
    "        loss = criterion_char(output, mean_im)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        current_loss += loss.item()\n",
    "        psnr += calculate_psnr(output.detach().cpu().numpy()*255, \\\n",
    "                               mean_im.detach().cpu().numpy()*255, border=0)\n",
    "        niter += 1\n",
    "        if niter % 100 == 0:\n",
    "            loss_mean.append(current_loss/100)\n",
    "            psnr_mean.append(psnr/100)\n",
    "            out = output[0,...].data.squeeze().float().cpu().clamp_(0, 1).numpy() * 255\n",
    "            out = np.transpose(out, (1, 2, 0)).round().astype(np.uint8)\n",
    "            out_save = Image.fromarray(out)\n",
    "            out_save.save(f'./image/init_imgs/img_{niter}.jpg', \"JPEG\")\n",
    "            \n",
    "            print('iteration: {:d} lr: {:.8f} loss-100-iter: {:.8f} psnr-100-iter: {:4f}'.format(\n",
    "                niter, optimizer.param_groups[0]['lr'], current_loss/100, psnr/100))\n",
    "            if psnr/100 > best_psnr:\n",
    "                torch.save({'step': niter, \n",
    "                            'best_psnr': psnr/100,\n",
    "                            'state_dict': gen_net.state_dict(),\n",
    "                            'optimizer' : optimizer.state_dict()\n",
    "                            }, f\"best_res.pth\")      \n",
    "                best_psnr = psnr/100\n",
    "            current_loss = 0\n",
    "            psnr = 0\n",
    "    if niter >= max_iters:\n",
    "        break\n",
    "        \n",
    "torch.save({'step': niter, \n",
    "            'state_dict': gen_net.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict()\n",
    "            }, f\"model_step_{niter}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bf0347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061861cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03842d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
